{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dermatologist-level Classification of Skin Cancer with Deep Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Abstract\n",
    "\n",
    "인간에게 가장 흔한 악성종양인 피부암은 최초 임상영상 및 피부경검분석, 생체검사, 그리고 조직검사를 통해 눈으로 직접 진단한다. 이미지를 사용한 피부병변 자동분류는 병변 외양의 굉장히 세분화된 형태 때문에 어려운 작업이다. CNN은 많은 세분화된 오브젝트를 구분하는 일반적이고 다양한 작업들에 대해 잠재능력을 가지고 있다. 우리의 연구내용은 다음과 같다.\n",
    "\n",
    "1. **모델** : 병명이 라벨링된 이미지들을 end-to-end 학습시킨 단일 CNN 모델\n",
    "2.  **목적** : 두 가지 영역(피부세포암 vs 양성피부각질, 악성흑색종 vs 양성반점)에서의 Binary Classification 작업\n",
    "  + 1st case : 가장 흔한 암\n",
    "  + 2nd case : 가장 치명적인 암\n",
    "<br><br> \n",
    "3.  **데이터셋** : 2032종류의 질병으로 구성된 129450개의 의료 이미지\n",
    "4.  **검증** : 자격을 갖춘 21명의 피부과 전문의들과 비교\n",
    "5.  **결과** : 두 영역 모두 전문의 수준의 정확도를 보여줌 -> 모바일 환경에서 잠재적으로 사용될 수 있을 것 -> 병원에 가지 않고 진단받을 수 있는 날이 올 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. 기존 연구와의 차별점\n",
    "\n",
    "### (1) 표준화된 이미지 불필요\n",
    "\n",
    "과거 피부과 컴퓨터 분류 시스템들은 **불충분한 데이터**와 더모스코피와 피부조직이미지분류라는 **표준화된 업무에 집중**했기 때문에 일반화 능력이 떨어진다. 더모스코피는 특수장비를 통해, 피부조직이미지는 외과적 생체검사와 현미경을 통해 얻어지며 둘 다 표준화된 이미지를 산출해낸다. 반면 스마트폰 이미지 같은 사진자료는 여러 요소들(줌, 각도, 조명 등)의 영향으로 다양하기 때문에 분류하기 어렵다. 우리는 141만장으로 훈련된 data-driven approach를 사용해 다양성을 지닌 사진 이미지들을 robust하게 classify할 수 있었다.\n",
    "\n",
    "### (2) 전처리과정 불필요\n",
    "\n",
    "+ 기존 연구 : classification 이전에 여러 전처리과정(병변 segmentation, feature 추출 등)을 거침\n",
    "+ 이번 연구 : 전처리과정이 필요 없고 위에서 언급한 모델을 사용해 곧장 end-to-end로 훈련시킴\n",
    "\n",
    "### (3) General한 모델 구현\n",
    "\n",
    "+ 기존 연구 : 일반적으로 1000장 미만의 피부병변 이미지를 사용해 새로운 이미지에는 general하게 적용할 수 없음\n",
    "+ 이번 연구 : 3374개의 피부과 이미지를 포함한 129450개의 의료 이미지를 사용해 분류의 generality를 보장\n",
    "\n",
    "\n",
    "딥러닝 알고리즘은 최근 아타리게임, 바둑, 그리고 오브젝트 인식 등의 시각적 작업에서 사람의 정확도를 넘어서고 있다. 피부과 전문의 수준의 정확도를 이뤄낸 분야도 존재한다. 흑색종 분류, 더모스코피를 활용한 흑색종 분류, 암종 분류가 그것이다. (단, '이미지 기반' 분류 한정)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. 연구과정 및 결과\n",
    "\n",
    "+ **모델** : 1000가지 클래스의 약 128만개의 이미지로 pre-train된 GoogleNet Inception v3 (2014 ImageNet Challenge에 사용된 모델)을 **Transfer Learning**을 통해 학습시킴\n",
    "<br><br>\n",
    "+ **데이터셋**\n",
    "  + 757종류의 질병 클래스로 훈련됨\n",
    "  + 피부과 전문의에 의해 2032종류의 세부 클래스들이 트리구조로 표현됨\n",
    "  + Stanford University Medical Center를 비롯해 전문의의 검수 하에 온라인으로 공개된 18개의 서로 다른 데이터셋들을 합쳐서 사용\n",
    "  + 127463개의 training set과 1942개의 validation set으로 구성\n",
    "<br><br>\n",
    "+ **알고리즘** : 분류된 질병을 위에서 언급한 세부 클래스로 나누기 위한 알고리즘\n",
    "  + 이미지를 입력받아 그것이 어떤 세부 클래스에 속하는지 확률분포로 출력\n",
    "  + 이후 자식 노드들의 확률을 더해 어떤 상위 클래스에 속하는지 결정\n",
    "<br><br>\n",
    "+ **검증** : 두 가지 방식 사용한 9-fold cross-validation\n",
    "  + 3-class disease partition : 1레벨 트리 - 양성 병변, 악성 병변, 비종양 병변을 분류\n",
    "  + 9-class disease partition : 2레벨 트리 - 어떤 처방을 받아야할지 분류\n",
    "<br><br>\n",
    "+ **결과**\n",
    "  + 3-class disease partition : 72.1% (두 전문의는 각각 65.56%, 66.0% 기록)\n",
    "  + 9-class disease partition : 55.4% (두 전문의는 각각 53.3%, 55.0% 기록)\n",
    "  + 트리구조의 세부클래스로 학습된 CNN이 3-class나 9-class로 학습된 녀석보다 성능이 좋았음\n",
    "  + Validation Set의 라벨은 생검이 아닌 전문의에 의해 매겨졌기 때문에 불완전한 결과임!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
