{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dermatologist-level Classification of Skin Cancer with Deep Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Abstract\n",
    "\n",
    "인간에게 가장 흔한 악성종양인 피부암은 최초 임상영상 및 피부경검분석, 생체검사, 그리고 조직검사를 통해 눈으로 직접 진단한다. 이미지를 사용한 피부병변 자동분류는 병변 외양의 굉장히 세분화된 형태 때문에 어려운 작업이다. CNN은 많은 세분화된 오브젝트를 구분하는 일반적이고 다양한 작업들에 대해 잠재능력을 가지고 있다. 우리의 연구내용은 다음과 같다.\n",
    "\n",
    "1. **모델** : 병명이 라벨링된 이미지들을 end-to-end 학습시킨 단일 CNN 모델\n",
    "2.  **목적** : 두 가지 영역(피부세포암 vs 양성피부각질, 악성흑색종 vs 양성반점)에서의 Binary Classification 작업\n",
    "  + 1st case : 가장 흔한 암\n",
    "  + 2nd case : 가장 치명적인 암\n",
    "<br><br> \n",
    "3.  **데이터셋** : 2032종류의 질병으로 구성된 129450개의 의료 이미지\n",
    "4.  **검증** : 자격을 갖춘 21명의 피부과 전문의들과 비교\n",
    "5.  **결과** : 두 영역 모두 전문의 수준의 정확도를 보여줌 -> 모바일 환경에서 잠재적으로 사용될 수 있을 것 -> 병원에 가지 않고 진단받을 수 있는 날이 올 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. 기존 연구와의 차별점\n",
    "\n",
    "### (1) 표준화된 이미지 불필요\n",
    "\n",
    "과거 피부과 컴퓨터 분류 시스템들은 **불충분한 데이터**와 더모스코피와 피부조직이미지분류라는 **표준화된 업무에 집중**했기 때문에 일반화 능력이 떨어진다. 더모스코피는 특수장비를 통해, 피부조직이미지는 외과적 생체검사와 현미경을 통해 얻어지며 둘 다 표준화된 이미지를 산출해낸다. 반면 스마트폰 이미지 같은 사진자료는 여러 요소들(줌, 각도, 조명 등)의 영향으로 다양하기 때문에 분류하기 어렵다. 우리는 141만장으로 훈련된 data-driven approach를 사용해 다양성을 지닌 사진 이미지들을 robust하게 classify할 수 있었다.\n",
    "\n",
    "### (2) 전처리과정 불필요\n",
    "\n",
    "+ 기존 연구 : classification 이전에 여러 전처리과정(병변 segmentation, feature 추출 등)을 거침\n",
    "+ 이번 연구 : 전처리과정이 필요 없고 위에서 언급한 모델을 사용해 곧장 end-to-end로 훈련시킴\n",
    "\n",
    "### (3) General한 모델 구현\n",
    "\n",
    "+ 기존 연구 : 일반적으로 1000장 미만의 피부병변 이미지를 사용해 새로운 이미지에는 general하게 적용할 수 없음\n",
    "+ 이번 연구 : 3374개의 피부과 이미지를 포함한 129450개의 의료 이미지를 사용해 분류의 generality를 보장\n",
    "\n",
    "\n",
    "딥러닝 알고리즘은 최근 아타리게임, 바둑, 그리고 오브젝트 인식 등의 시각적 작업에서 사람의 정확도를 넘어서고 있다. 피부과 전문의 수준의 정확도를 이뤄낸 분야도 존재한다. 흑색종 분류, 더모스코피를 활용한 흑색종 분류, 암종 분류가 그것이다. (단, '이미지 기반' 분류 한정)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. 실험\n",
    "\n",
    "+ **모델** : 1000가지 클래스의 약 128만개의 이미지로 pre-train된 GoogleNet Inception v3 (2014 ImageNet Challenge에 사용된 모델)을 **Transfer Learning**을 통해 학습시킴\n",
    "<br><br>\n",
    "+ **분류체계**\n",
    "  + 피부과 전문의에 의해 분류되어 **트리구조**로 표현된 2032종류의 세부 클래스들을 분류체계(taxomony)로 사용\n",
    "  + 분류체계 중 757종류의 클래스로만 훈련됨 (그림 참조)\n",
    "<br><br>\n",
    "+ **데이터셋**\n",
    "  + Stanford University Medical Center를 비롯해 전문의의 검수 하에 온라인으로 공개된 18개의 서로 다른 데이터셋들을 합쳐서 사용\n",
    "  + 127463개의 training set과 1942개의 validation set으로 구성\n",
    "<br><br>\n",
    "+ **알고리즘** : 분류된 질병을 위에서 언급한 세부 클래스로 나누기 위한 알고리즘\n",
    "  + 이미지를 입력받아 그것이 어떤 세부 클래스에 속하는지 확률분포로 출력\n",
    "  + 이후 자식 노드들의 확률을 더해 어떤 상위 클래스에 속하는지 결정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. 검증 및 결과\n",
    "\n",
    "+ **1차 검증** : 두 가지 방식을 사용한 9-fold cross-validation\n",
    "  + 3-class disease partition : 1레벨 트리 - 양성 병변, 악성 병변, 비종양 병변을 분류\n",
    "  + 9-class disease partition : 2레벨 트리 - 더 구체적인 병명 진단\n",
    "<br><br>\n",
    "+ **1차 결과**\n",
    "  + 3-class disease partition : 72.1% (두 전문의는 각각 65.56%, 66.0% 기록)\n",
    "  + 9-class disease partition : 55.4% (두 전문의는 각각 53.3%, 55.0% 기록)\n",
    "  + 세부 클래스로 학습된 CNN이 3-class나 9-class로만 학습된 녀석보다 성능이 좋았음\n",
    "<br><br>\n",
    "+ **2차 검증** : Validation Set의 라벨은 생검이 아닌 전문의에 소견에 의해 매겨졌기 때문에 불완전한 결과이다! 확실한 검증을 위해 생검으로 증명된 이미지만 사용해 두 주제(피부세포암 vs 양성피부각질, 악성흑색종 vs 양성반점)에 거쳐 binary classification을 수행했다. \n",
    "  + sensitivity : true positive / positive (악성병변을 맞춘 비율)\n",
    "  + specificity : true negative / negative (양성병변을 맞춘 비율)\n",
    "<br><br>  \n",
    "+ **2차 결과** : AUC curve로 분석한 결과, 많은 경우 우리의 알고리즘이 전문의를 넘어섰다는 걸 알 수 있다. (blue curve 밑에 있는 전문의들은 CNN보다 낮은 정확도를 기록했음을 의미함)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. 결론\n",
    "\n",
    "단 하나의 CNN으로, 그것도 일반적인 상황에서 딥러닝의 효과를 증명했다. 또 세 가지 binary classification 문제에서 21명의 전문의에 뒤지지 않는 성능을 이루었다. 이렇게 빠르고 비례확장성을 가진 방법을 모바일 기기에 이식한다면 초기 진단이 가능하고 전문의들이 처방을 내리는 데 도움을 줄 수 있을 것이다. 이 방법은 근본적으로 불완전한 데이터에 의해 다소 제한되었지만, 충분한 훈련 데이터가 존재한다면 더 많은 분류를 가능케 할 것이다. 딥러닝은 이미지 데이터의 타입에 따라 agnostic하기에 안과, 이비인후과, 방사선학과 및 병리학에도 적용될 수 있을 것이다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
