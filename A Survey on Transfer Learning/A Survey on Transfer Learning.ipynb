{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Survey on Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Abstract\n",
    "\n",
    "머신러닝 및 데이터 마이닝 알고리즘에서의 주요한 선행 가정 중 하나는 훈련 데이터와 미래 데이터의 feature space 및 distribution이 일치해야 한다는 것이다. 하지만 실제 응용분야에서 이 가정은 유지되지 않을 수 있다. 예를 들어, 우리가 어떤 관심분야에서 classification을 하고 싶은데, feature space와 distribution이 같지 않은 다른 분야의 훈련 데이터만 가지고 있을 수 있다. 이런 경우 knowledge transfer가 성공적으로 이루어질 수 있다면 새로 데이터를 라벨링하는 비싼 댓가를 치루지 않고도 성능을 향상시킬 수 있다. 최근 transfer learning은 이런 문제를 해결하기 위한 새로운 학습 프레임워크로서 등장했다. \n",
    "\n",
    "이 서베이는 다음과 같은 내용을 담는다.\n",
    "+ **classification, regression, 그리고 clustering 문제에 관한 transfer learning**의 트렌드\n",
    "+ transfer learning과 다른 **ML테크닉**(domain adaptation, multitask learning, sample selection bias, co-variate shift 등)들 사이의 관계\n",
    "+ transfer learning에 대한 **잠재적인 미래 이슈들**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Introduction\n",
    "\n",
    "데이터 마이닝과 머신러닝 기술들은 이미 classification, regression 그리고 clustering 등의 많은 지식공학 분야에서 뛰어난 성공을 이뤄내고 있다. 하지만 많은 머신러닝 기술들은 오직 훈련 데이터와 테스트 데이터가 같은 feature space와 distribution을 가진다는 가정 하에서만 제대로 작동한다. distribution이 바뀌면 대부분의 통계학적 모델들은 데이터 수집 과정부터 재구성되어야 한다. 많은 실제 응용분야에서 이런 작업은 비싸거나 아예 불가능할 수도 있다. 데이터 수집 과정을 줄일 수 있다면 멋질 것이다! 이런 경우 knowledge transfer a.k.a transfer learning을 추천하는 바이다.\n",
    "\n",
    "1. **Web Document Classification** : 주어진 웹문서들을 사전 정의된 카데고리로 분류해야 하는 해당 작업에서는, 예전에 다른 카데고리로 라벨링된 데이터를 이용해야 할 수 있다. 이 때 transfer learning을 사용한다면 현재 사용하는 카데고리로 새로 라벨링하는 수고를 덜 수 있다.\n",
    "\n",
    "2. **Indoor WiFi Localization** : 이전에 모은 사용자의 위치 데이터로 현재 위치를 예측해야 하는 작업이다. 이전 데이터가 현재 데이터와 분포가 달라지기 때문에 데이터가 쉽게 구식이 된다. 큰 규모의 환경에서 건물 내 위치에 따른 와이파이 데이터를 수집하는 일은 매우 비싸다. 각 장소마다의 와이파이 신호를 직접 라벨링 해야하기 때문이다. 또한 와이파이 신호는 시간, 기기 등 동적 변수에 의한 함수이므로 이전 데이터로 학습시킨 모델로 현재를 예측하게 되면 정확도가 떨어질 수 있다. 따라서 transfer learning이 필요하다.\n",
    "\n",
    "3. **Sentiment Classification** : 어떤 제품에 대한 리뷰를 자동 분류해주는 작업에서, 우리는 먼저 수많은 리뷰들을 모아 긍정적인지 부정적인지 라벨링 해야 한다. 제품 종류마다 리뷰 데이터 분포가 다르기 때문에 각 제품마다 많은 양의 데이터를 필요로 한다. 하지만 한 제품의 리뷰를 다른 제품의 분류 예측에 사용할 수 있다면 데이터를 준비하는 수고를 덜 수 있다.\n",
    "\n",
    "\n",
    "이 서베이에서는 classification, regression, clustering 문제에 대한 transfer learning 및 data mining과 관련된 문제만을 다룰 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Overview\n",
    "\n",
    "### (1) 전이학습의 역사\n",
    "\n",
    "전통적인 데이터마이닝과 머신러닝 알고리즘은 이전에 수집된 training data로 학습된 통계모델을 사용해 미래의 데이터를 예측했다. Semi-supervised classification은 많은 양의 unlabeled data와 적은 양의 labeled data를 이용해 labeled data가 너무 적을 때의 문제를 해결했다. 불완전한 데이터셋을 위한 학습방법 연구는 다음과 같이 이루어졌다.\n",
    "\n",
    "+ Zhu and Wu : noisy class-label problem을 다루는 방법 연구\n",
    "+ Yang et al. : 미래 데이터에 추가 test를 할 수 있도록 cost-sensitive learning 제안\n",
    "\n",
    "하지만 이런 대부분의 연구들은 데이터들의 distribution이 같다는 가정 하에 이루어졌다. 반면 Transfer Learning은 데이터들간의 domain, task, distribution이 다르더라도 작동한다. 예를 들어 실생활에서, 사과를 인식하는 능력은 배를 인식하는데 도움을 줄 수 있고, 키보드 연주 능력이 피아노 연주에 도움을 줄 수 있다. Transfer Learning 연구는 이러한 사람들의 영리한 학습능력에서 영감을 얻었다. 이 개념이 최초로 언급된 곳은 이전에 학습한 지식을 재사용하는 lifelong machine-learning method의 필요성에 대해 조명한 NIPS-95 워크샵의 \"Learning to Learn\" 에서였다.\n",
    "\n",
    "TL은 1995년부터 다양하게 연구되며 점점 더 많은 관심을 끌었다. 이 중 현재의 TL과 가장 유사한 기술은 서로 다른 임무들을 동시에 학습시키기 위한 Multi-Task Learning Framework였다. 이 연구의 일반적인 접근법은 각각의 독립적인 작업들에 이득이 되는 공통 feature들을 찾아내는 일이었다.\n",
    "\n",
    "2005년 DARPA(미 국방고등연구계획국) IPTO(정보처리기술부)의 BAA(Broad Agency Announcement) 05-29는 TL에 새로운 임무를 부여했다. 이전 작업에서 학습한 지식과 기술을 새로운 작업에 적용시키는 시스템으로서의 능력을 갖추는 것이다. 이 정의에서 TL은 하나 혹은 그 이상의 source tasks로부터 지식을 추출해 target task에 적용하는 것을 목표로 한다. source와 target을 동시에 학습시키는 multi-task learning과는 다르게 TL은 target에 더 많은 신경을 쓴다. TL에서 source와 target은 더 이상 동일시 되지 않는다.\n",
    "\n",
    "Fig 1은 전통적인 ML과 TL 사이의 차이를 보여준다. 전통적인 ML은 각각의 작업들을 전부 처음부터 학습하는 반면, TL은 좋은 품질의 훈련데이터가 부족할 경우 이전 작업에서의 지식을 target task에 전이시킨다.\n",
    "\n",
    "오늘날 TL 방법론은 탑 컨퍼런스에 등장하곤 한다. \n",
    "\n",
    "+ Data Mining 분야 : ACM KDD, IEEE ICDM, PKDD 등\n",
    "+ Machine Learning 분야 : ICML, NIPS, ECML, AAAI, IJCAI 등\n",
    "+ DM & ML 응용분야 : ACM SIGIR, WWW, ACL 등\n",
    "\n",
    "\n",
    "### (2) 전이학습의 종류\n",
    "\n",
    "+ **Inductive Transfer Learning** : target에 라벨링된 데이터가 있는 경우\n",
    "  + Self-taught Learning : source에는 라벨링된 데이터가 없는 경우\n",
    "  + Multi-task Learning : source에도 라벨링된 데이터가 있는 경우\n",
    "+ **Transductive Transfer Learning** : source에만 라벨링된 데이터가 있는 경우\n",
    "  + Domain Adaptation : 도메인은 다르지만 목적(task)은 같은 경우\n",
    "  + Sample Selection Bias / Covariance Shift : 도메인도 다르고 목적(task)도 다른 경우\n",
    "+ **Unsupervised Transfer Learning** : source와 target 모두 라벨링된 데이터가 없는 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Inductive Transfer Learning\n",
    "\n",
    "### (1) 인스턴스 정보(Knowledge of Instances) 전달\n",
    "\n",
    "Inductive TL이란 source domain으로 targer domain의 task의 학습을 향상시키는 방법으로 가장 일반적인 TL이다. target의 데이터가 부족할 때 사용하며 크게 두 경우로 나뉜다.\n",
    "\n",
    "+ source의 라벨링된 데이터를 사용 가능한 경우 (이 경우가 가장 흔함)\n",
    "+ source의 라벨링 되지 않은 데이터만 사용 가능한 경우\n",
    "\n",
    "\n",
    "+ **Dai et al.** : AdaBoost 알고리즘을 확장한 TrAdaBoost를 제안했다. 이것은 두 도메인의 'feature'와 'label'은 같지만 'distribution'은 다를 경우 사용할 수 있다. 그래서 두 도메인의 distrubution의 차이 때문에 몇몇 source 도메인의 데이터는 target 도메인 학습에 도움이 될 수 있지만 반대로 학습에 악영향을 끼칠 수도 있다. 그렇기에 해로운 source 데이터의 가중치를 줄여 유용한 데이터의 영향력을 높이는 방식을 사용했다. 학습이 이루어질 때마다 TrAdaBoost는 가중치가 다르게 적용된 source 데이터를 target에 학습시킨다. \n",
    "+ **Jiang and Zhai** : 조건확률을 사용해 해로운 학습데이터를 제거하는 경험적 방법론을 제안\n",
    "+ **Liao et al.** : source 데이터를 이용해 target의 라벨링 되지 않은 데이터를 라벨링하는 학습방법 제안\n",
    "+ **Wu and Dietterich** : source 데이터를 SVM 프레임워크와 조합해 분류성능향상\n",
    "\n",
    "\n",
    "### (2) 특징정보(Feature-Representation-Transfer)를 전달\n",
    "\n",
    "Feature-Representation-Transfer는 도메인의 발산과 분류 및 회귀모델의 에러를 최소화하는 '좋은 특징'을 찾아내는 과정이다. 이 전략은 source 데이터의 종류에 따라 다르게 적용된다. **source 데이터에 라벨링된 데이터가 많으면 지도학습**을 사용한다. 이것은 multi-task learning 분야의 common feature learning과 유사하다. 반대로 **source 데이터에 라벨링 데이터가 없으면 비지도학습**을 사용한다.\n",
    "\n",
    "#### 1. Supervised Feature Construction\n",
    "기본 아이디어는 두 도메인에 공통되는 낮은 차원의 특징을 학습시켜 분류 및 회귀모델의 에러를 줄이는 것이다. 공통특징은 최적화문제를 풀어 학습시킬 수 있다.\n",
    "\n",
    "+ Argyriou et al. : multi-task learning에 spactral regularization framework를 적용\n",
    "+ Lee et al. : convex optimization 알고리즘 사용\n",
    "+ Jebara : multi-task learning에 SVM을 적용\n",
    "+ Ruckert et al. : target 데이터에 적절한 커널을 찾는 걸 목표로 함\n",
    "\n",
    "#### 2. Unsupervised Feature Construction\n",
    "\n",
    "+ Raina et al. : sparse coding을 적용해 높은 레벨의 특징을 학습시키는 방법을 제안했다. 최적화문제를 풀어 고레벨의 basis vector들을 찾아내고, 여기에 해당하는 특징들을 최적화 알고리즘을 통해 target 데이터에 학습시킨 뒤, 분류 및 회귀모델을 학습시킨다. 하지만 source에서 뽑아낸 이른바 고레벨 벡터들이 target에 알맞지 않을 수 있다는 한계가 있다.\n",
    "+ Wang and Mahadevan : 두 도메인 데이터의 maniford alignment에 Procrustes 분석법을 적용\n",
    "\n",
    "\n",
    "\n",
    "### (3) 파라미터정보(Knowledge of Parameters)를 전달\n",
    "\n",
    "두 도메인의 모델들은 변수나 매개변수의 prior distribution을 공유해야 한다는 생각에서 연구되었다. 이 서베이에 소개된 대부분의 접근법들은 multi-task learning을 위해 고안된 것이지만 transfer learning에 쉽게 수정해 적용할 수 있다. MTL과 TL의 차이점은, MTL의 경우 두 도메인을 동시에 완벽하게 학습시키는 것이 목적이지만, TL의 경우 source의 데이터를 활용해 target의 성능을 향상시키는 것만을 목적으로 한다는 것이다. 그러므로 MTL에서 source와 target의 loss function 가중치는 동일한 반면, TL에서는 가중치가 다를 수 있다. 직관적으로 target의 loss function 가중치를 늘리는 것이 더 나은 성능을 낼 것이다.\n",
    "\n",
    "+ Lawrence and Platt : GP(Gaussian Processes)에 기반한 MT-IVM이라는 알고리즘을 제안했다. \n",
    "+ Bonilla et al. : GP에 multi-task learning을 도입했다.\n",
    "+ Schwaighofer et al. : GP에 multi-task learning을 도입하고 HB(계층적 베이지언 프레임워크)를 사용했다.\n",
    "+ Evgeniou and Pontil : HB의 아이디어를 빌려 multi-task learning에서 SVM을 사용했다.\n",
    "+ Gao et al. : TL에 많은 모델들을 결합하기 위해 locally weighted ensemble learning framework를 제안했다. target에 대한 모델의 예측강도에 따라 동적으로 가중치를 할당한다.\n",
    "\n",
    "\n",
    "### (4) 관계정보(Relational Knowledge)를 전달\n",
    "\n",
    "위 세 경우와 다르게 관련된 도메인들 간의 TL문제를 다룬다. 즉 각각의 도메인들이 i.i.d.(independent & identically distributed)하다고 가정한다. 이 분야는 도메인 데이터 사이의 '관계(relationship)'를 전달하는 것이 목적이다. 예를 들어, 한 도메인에서의 교수-학생의 관계는 다른 도메인에서 관리자-노동자의 관계와 유사할 수 있다.\n",
    "\n",
    "+ Mihalkova et al. : 관계정보를 MLN(Markov Logic Network)을 이용해 전달하는 TAMAR 알고리즘을 제안했다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Transductive Transfer Learning\n",
    "\n",
    "이 분야는 domain은 서로 다르지만 task는 같은 경우를 가정한다. 또한 target쪽에 사용 가능한 unlabeled 데이터가 있어야 한다.\n",
    "\n",
    "### (1) 인스턴스 정보(Knowledge of Instances) 전달\n",
    "\n",
    "우리는 target의 loss function을 최소화시켜야 하는데 target의 labeled 데이터가 없으므로 source의 데이터로 학습을 시킬 것이다. 그 확률분포가 같다면 간단한 최적화문제를 해결해서 학습을 시킬 수 있고, 확률분포가 다르다면 source와 target의 확률분포의 비율을 계산해 수정된 최적화문제를 해결해서 학습시킬 수 있다. 확률분포비를 측정하는 다양한 방법들이 존재한다.\n",
    "\n",
    "+ Zadrozny : 각 확률분포를 따로 계산해 간단한 분류 문제를 해결\n",
    "+ Huang et al. : KMM(kernel-mean matching) 알고리즘으로 KLIEP(Kullback-Leibler divergence)를 이용해 source와 target간의 평균을 맞춤으로써 한번에 확률분포비를 구한다. KLIEP는 source의 가중치를 산정하고, 그 가중치를 재조정해 모델을 학습시키는 두 단계로 이루어진다.\n",
    "+ Bickel et al. : kernel-logistic regression classifier를 확장시켜 위 연구의 두 단계를 한 번에 해결\n",
    "+ Dai et al. : Naive Bayesian classifier를 확장시킨 연구\n",
    "+ Quionero-Candela et al. : 최근 importance sampling과 가중치 재조정 방법론에 대한 책을 출간함\n",
    "+ Fan and Sugiyama : ICDM-08에서 Sample Selection Bias를 사용한 튜토리얼에서 도움을 받을 수 있음\n",
    "\n",
    "\n",
    "### (2) 특징정보(Feature-Representation-Transfer)를 전달\n",
    "\n",
    "이 분야의 연구는 대부분이 비지도 학습 프레임워크로 접근했다.\n",
    "\n",
    "+ Blitzer et al. : SCL(structural correspondence learning)으로 target의 unlabeled data로부터 도메인간 차이를 줄일 수 있는 연관된 특징들을 뽑아냄\n",
    "+ Ben-David and Schuller : 실험으로 SCL이 도메인간 차이를 줄일 수 있음을 증명\n",
    "+ Daume : NLP 분야에서 source와 target의 데이터로부터 고치원 특징 맵을 뽑아내, 분류기를 학습시키는데 서로 다른 방법을 사용함\n",
    "+ Dai et al. : 서로 다른 도메인 간의 라벨링 정보를 전달하기 위한 co-clustering 기반 알고리즘 제안\n",
    "+ Xing et al. : bridged refinement라고 알려진 최신 알고리즘을 제안\n",
    "+ Ling et al. : spectral classification framework를 제안\n",
    "+ Xue et al. : 고전적인 PLSA(probabilistic latent semantic analysis) 알고리즘을 확장시켜 Topic-bridged PLSA를 제안해, 서로 다르지만 어느정도 관련은 있는 도메인들의 labeled, unlabeled 데이터를 통합\n",
    "+ Pan et al. : MMDE(Maximum Mean Discrepancy Embedding)방식을 사용한 차원축소를 통해 TL문제를 해결했지만 연산 과부하가 우려됨\n",
    "+ Pan et al. : 이후 연산량을 줄인 TCA(Transfer Component Analysis) 제안"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Unsupervised Transfer Learning\n",
    "\n",
    "source와 target 어느 쪽에서 라벨링 데이터가 없다. 이 분야는 현재까지 많은 연구가 진행되지 않았다.\n",
    "\n",
    "\n",
    "### (1) 특징정보(Feature-Representation-Transfer)를 전달\n",
    "\n",
    "+ Dai et al. : Self-taught Clustering으로 transfer clustering을 다룸\n",
    "+ Transferred Discriminative Analysis : transfer dimensionality reduction problems를 다룸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Transfer Bounds and Negative Transfer\n",
    "\n",
    "### (1) Transfer Bound\n",
    "\n",
    "+ Hassan Mahmud and Ray : Kolmogorov complexity를 사용해 TL을 분석해 이론적인 한계를 증명\n",
    "+ Eaton et al. : graph-based method를 제안해 TL 전에 그래프에 task를 매핑시켜 parameter를 결정해줌\n",
    "\n",
    "### (2) Negative Transfer\n",
    "\n",
    "이 분야의 연구는 매우 중요하지만 많이 이루어지지 않았다.\n",
    "\n",
    "+ Rosenstein et al. : 두 task가 너무 다르면 브루트포스 transfer는 악영향을 미칠 수 있음을 보임\n",
    "+ Bakker and Heskes : Bayesian 접근법으로 모든 task가 공유하는 파라미터와 덜 연결된 파라미터를 알아내 파라미터 기준으로 task를 clustering한다. 같은 cluster에 속한 task는 서로 유사하므로 negative transfer를 피할 수 있다.\n",
    "+ Argyriou et al. : task를 group으로 나눈다. 한 group 내의 task들은 같은 저레벨 특징을 공유하고, 그룹마다 공유하는 저레벨 특징들이 다르다. 이렇게 task간 유사도를 알아내 negative transfer를 피할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. 적용분야\n",
    "\n",
    "+ **적용분야** : 텍스트 데이터, 자연어처리, 이미지 분류, Name-Entity 인식문제, WiFi localization, CAD, 자동번역 등\n",
    "+ **국제대회** : ECML/PKDD-2006 discovery challenge(스팸메일 여부를 분류), ICDM-2007 Contest(실내 WiFi 사용자 위치예측)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. 결론\n",
    "\n",
    "+ 전이학습은 Inductive, Transductive, Unsupervised 세 종류로 나뉘고, 앞의 두 분야가 대부분이다. 비지도전이학습은 미래에 더 많은 관심을 끌게 될 것이다.\n",
    "+ 각 분야마다 '무엇을 전이시킬 것인지'를 구분지어 설명했는데, instance, feature, parameter, relational knowledge가 그것이다. 앞의 세 가지는 데이터가 i.i.d.하다는 가정 하에 진행되었다.\n",
    "+ 미래에는 **negative transfer**를 피하는 방법이 가장 중요한 이슈로 떠오를 것이다.\n",
    "+ 보통 feature space는 같지만 distribution이 다른 환경에서 대부분의 연구가 진행되었는데, **feature space가 다른 여러 도메인**에서 전이학습을 시키는 heterogeneous TL에 대한 연구가 진행되어야 할 것이다.\n",
    "+ 현재 텍스트, 네트워크, 이미지분류 등의 적은 분야에만 적용되고 있지만, 비디오분류, SNS 분석, 논리추론 등 그 범위가 더 늘어나게 될 것이다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
