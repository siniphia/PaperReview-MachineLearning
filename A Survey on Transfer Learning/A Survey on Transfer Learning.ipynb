{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Survey on Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Abstract\n",
    "\n",
    "머신러닝 및 데이터 마이닝 알고리즘에서의 주요한 선행 가정 중 하나는 훈련 데이터와 미래 데이터의 feature space 및 distribution이 일치해야 한다는 것이다. 하지만 많은 실생활 어플리케이션에서 이 가정은 유지되지 않을 수 있다. 예를 들어, 우리가 어떤 관심분야에서의 분류 문제를 해결해야 할 때, feature space와 distribution이 같지 않은 또다른 관심분야의 훈련 데이터만 충분하게 가지고 있을 수 있다. 이런 경우 knowledge transfer가 성공적으로 이루어질 수 있다면 새로 데이터를 라벨링하는 비싼 댓가를 치루지 않고도 성능을 향상시킬 수 있다. 최근 transfer learning은 이런 문제를 해결하기 위한 새로운 학습 프레임워크로서 등장했다. \n",
    "\n",
    "이 서베이는 다음과 같은 내용을 담는다.\n",
    "+ **classification, regression, 그리고 clustering 문제에 관한 transfer learning**의 트렌드\n",
    "+ transfer learning과 다른 **ML테크닉**(domain adaptation, multitask learning, sample selection bias, co-variate shift 등)들 사이의 관계\n",
    "+ transfer learning에 대한 **잠재적인 미래 이슈들**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Introduction\n",
    "\n",
    "데이터 마이닝과 머신러닝 기술들은 이미 classification, regression 그리고 clustering 등의 많은 지식공학 분야에서 뛰어난 성공을 이뤄내고 있다. 하지만 많은 머신러닝 기술들은 오직 훈련 데이터와 테스트 데이터가 같은 feature space와 distribution을 가진다는 가정 하에서만 제대로 작동한다. distribution이 바뀌면 대부분의 통계학적 모델들은 데이터 수집 과정부터 재구성되어야 한다. 많은 실생활 어플리케이션에서 이런 작업은 비싸거나 아예 불가능할 수도 있다. 데이터 수집 과정을 줄일 수 있다면 멋질 것이다! 이런 경우 knowledge transfer 또는 transfer learning을 추천하는 바이다.\n",
    "\n",
    "1. **Web Document Classification** : 주어진 웹문서들을 사전 정의된 카데고리로 분류해야 하는 해당 작업에서는, 예전에 다른 카데고리로 라벨링된 데이터를 이용해야 할 수 있다. 이 때 transfer learning을 사용한다면 현재 사용하는 카데고리로 새로 라벨링하는 수고를 덜 수 있다.\n",
    "\n",
    "2. **Indoor WiFi Localization** : 이전에 모은 사용자의 위치 데이터로 현재 위치를 예측해야 하는 작업이다. 이전 데이터가 현재 데이터와 분포가 달라지기 때문에 데이터가 쉽게 구식이 된다. 큰 규모의 환경에서 건물 내 위치에 따른 와이파이 데이터를 수집하는 일은 매우 비싸다. 각 장소마다의 와이파이 신호를 직접 라벨링 해야하기 때문이다. 또한 와이파이 신호는 시간, 기기 등 동적 변수에 의한 함수이므로 이전 데이터로 학습시킨 모델로 현재를 예측하게 되면 정확도가 떨어질 수 있다. 따라서 transfer learning이 필요하다.\n",
    "\n",
    "3. **Sentiment Classification** : 어떤 제품에 대한 리뷰를 자동 분류해주는 작업에서, 우리는 먼저 수많은 리뷰들을 모아 긍정적인지 부정적인지 라벨링 해야 한다. 제품 종류마다 리뷰 데이터 분포가 다르기 때문에 각 제품마다 많은 양의 데이터를 필요로 한다. 하지만 한 제품의 리뷰를 다른 제품의 분류 예측에 사용할 수 있다면 데이터를 준비하는 수고를 덜 수 있다.\n",
    "\n",
    "\n",
    "이 서베이에서는 classification, regression, clustering 문제에 대한 transfer learning을 다루고 data mining쪽과 관련된 문제만을 다룰 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Overview\n",
    "\n",
    "### (1) A Brief History of Transfer Learning\n",
    "\n",
    "전통적인 데이터마이닝과 머신러닝 알고리즘은 이전에 수집된 training data로 학습된 통계모델을 사용해 미래의 데이터를 예측했다. Semi-supervised classification은 많은 양의 unlabeled data와 적은 양의 labeled data를 이용해 labeled data가 너무 적을 때의 문제를 해결했다. 불완전한 데이터셋을 위한 학습방법 연구는 다음과 같이 이루어졌다.\n",
    "\n",
    "+ Zhu and Wu : noisy class-label problem을 다루는 방법 연구\n",
    "+ Yang et al. : 미래 데이터에 추가 test를 할 수 있도록 cost-sensitive learning 제안\n",
    "\n",
    "그럼에도 불구하고 대부분의 연구들은 데이터들의 분포가 같다는 가정 하에 이루어졌다. 반면 Transfer Learning은 데이터들간의 domain, task, distribution이 다르더라도 작동한다. 예를 들어 실생활에서, 사과를 인식하는 능력은 배를 인식하는데 도움을 줄 수 있고, 키보드 연주 능력이 피아노 연주에 도움을 줄 수 있다. Transfer Learning 연구는 이러한 사람들의 영리한 학습능력에서 영감을 얻었다. 이 개념이 최초로 언급된 곳은 이전에 학습한 지식을 재사용하는 lifelong machine-learning method의 필요성에 대해 조명한 NIPS-95 워크샵의 \"Learning to Learn\" 에서였다.\n",
    "\n",
    "TL은 1995년부터 다양하게 연구되며 점점 더 많은 관심을 끌었다. 이 중 현재의 TL과 가장 유사한 기술은 서로 다른 임무들을 동시에 학습시키기 위한 Multi-Task Learning Framework였다. 이 연구의 일반적인 접근법은 각각의 독립적인 작업들에 이득이 되는 공통 feature들을 찾아내는 일이었다.\n",
    "\n",
    "2005년 DARPA(미 국방고등연구계획국) IPTO(정보처리기술부)의 BAA(Broad Agency Announcement) 05-29는 TL에 새로운 임무를 부여했다. 이전 작업에서 학습한 지식과 기술을 새로운 작업에 적용시키는 시스템으로서의 능력을 갖추는 것이다. 이 정의에서 TL은 하나 혹은 그 이상의 source tasks로부터 지식을 추출해 target task에 적용하는 것을 목표로 한다. source와 target을 동시에 학습시키는 multi-task learning과는 다르게 TL은 target에 더 많은 신경을 쓴다. TL에서 source와 target은 더 이상 동일시 되지 않는다.\n",
    "\n",
    "Fig 1은 전통적인 ML과 TL 사이의 차이를 보여준다. 전통적인 ML은 각각의 작업들을 전부 처음부터 학습하는 반면, TL은 좋은 품질의 훈련데이터가 부족할 경우 이전 작업에서의 지식을 target task에 전이시킨다.\n",
    "\n",
    "오늘날 TL 방법론은 탑 컨퍼런스에 등장하곤 한다. \n",
    "\n",
    "+ Data Mining 분야 : ACM KDD, IEEE ICDM, PKDD 등\n",
    "+ Machine Learning 분야 : ICML, NIPS, ECML, AAAI, IJCAI 등\n",
    "+ DM & ML 응용분야 : ACM SIGIR, WWW, ACL 등\n",
    "\n",
    "\n",
    "### (2) Notations and Definitions\n",
    "\n",
    "여기서는 이 서베이에서 사용되는 표현과 정의에 대해 언급하려고 한다. 먼저 Domain과 Task부터 살펴보자.\n",
    "\n",
    "+ Domain : 도메인은 feature space X와 주변확률분포 P(X)로 구성된다. 예를 들어, 우리의 learning task가 문서분류라면"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
