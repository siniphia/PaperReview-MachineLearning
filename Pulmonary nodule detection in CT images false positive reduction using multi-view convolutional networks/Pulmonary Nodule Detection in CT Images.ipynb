{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pulmonary Nodule Detection in CT Images : False Positive Reduction Using Multi-View Convolutional Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "이 논문은 세 개의 서로 다른 기준으로 폐암 후보군을 뽑아내 병합하고 하나의 CNN으로 다시 학습시켜 암을 진단하는 CAD(Computer Aided Detection) 시스템을 제안한다. 이 논문을 포함해 일반적인 CAD 시스템은 두 단계를 거친다.\n",
    "1. **Nodule Candidate Detection** : 굉장히 민감하게 암 후보군을 탐지해낸다. 결과적으로 False Positive Data(암이 아닌데 암이라고 판단된 데이터)가 비교적 많이 포함된다. 여기에 속하는 간단한 기술로 Double Thresholding, Morphological Operation 등이 있다.\n",
    "2. **False Positive Reduction** : CAD의 정확도를 사실상 좌우하는 단계로 관련된 특징들을 뽑아내 지도학습시킨다.\n",
    "\n",
    "여기에 제안된 시스템은 다음과 같은 세부사항을 갖는다.\n",
    "1. **Nodule Candidate Detection** : 암 후보군을 골라내는 단계로서 무엇보다 중요한 점은 '암인데도 암이 아니라고 판단해 넘어가는 경우'를 없애는 것이다. 그래서 굉장히 까다롭게 암 후보군을 골라낸다. 이 시스템은 이미 개발된 세 종류(Solid, Subsolid, Large Solid)의 알고리즘을 갖다붙였음.\n",
    "\n",
    "2. **False Positive Reduction** : 보통 CT같은 3D 이미지 분석에 2D CNN을 사용할 때에는 3D를 세 종류의 평면(axial, sgittal, coronal view)으로 자른 단면들을 사용한다. 이 단면들은 각각 multi-view 구조의 모델에 들어가 학습에 사용된다. 이 결과들에 Fusion Method(late-fusion, commitee-fusion 등)를 적용해 진단을 내린다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Materials\n",
    "\n",
    "+ LIDC-IDRI, ANODE09, DLCST 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Methods\n",
    "\n",
    "### (1) Candidate Detection\n",
    "\n",
    "첫 번째 단계인 후보군 탐색은 이미 개발된 세 종류의 알고리즘(solid, subsolid, large)을 전부 사용한다. 데이터들은 세 개의 알고리즘을 통과하며 각각 **좌표**와 **결절확률**(nodule probability)이 계산되고, 이 확률값을 평균내 후보군 여부를 판단한다. 또한 한 데이터에서 결절들이 서로 너무 가까이 있으면 한 결절로 병합시킨다.\n",
    "+ **'Solid'** 결절은 Murphy et al.가 제안한 기술인데 폐의 각 voxel(3차원 좌표)마다 모양과 굴곡을 계산해 특정 임계값을 넘으면 결절로 구분한다.\n",
    "+ **'Subsolid'** 결절은 Jacobs et al.이 제안했다.\n",
    "  1. 두 density threshold를 적용해 관심영역을 얻어낸다.\n",
    "  2. 3D connected component analysis로 morphological opening을 한다.\n",
    "  3. 기존에 사용되던 알고리즘으로 결절 segmentation을 진행한다.\n",
    "  <br><br>\n",
    "+ **'Large'** 결절은 위 두 알고리즘으로 탐지가 어려우며, 특히 결절이 늑막에 붙어있을 경우 늑막과의 명도차가 적기 때문에 결절로 분류되지 않을 수 있다. 따라서 Setio et al.의 알고리즘을 구현해 사용했다.\n",
    "  1. rolling-ball 알고리즘으로 늑막에 위치한 결절을 segmentation한다.\n",
    "  2. density threshold를 적용해 관심영역을 얻어낸다.\n",
    "  3. 다단계(큰 결절부터 작은 결절)로 morphological opening을 해 후보군을 얻는다.\n",
    "  <br><br>\n",
    "  \n",
    "이렇게 많이 unbalanced된 데이터를 학습시킬 때 문제점 중 하나는 흔하게 등장하는 모양은 잘 잡아내는데, 희귀한 모양은 그렇지 못하다는 것이다. 따라서 오버피팅을 방지하기 위해 결절확률이 낮은 데이터를 제거했다.*(왜 제거하지,,?)*\n",
    "\n",
    "\n",
    "### (2) Patches Extraction\n",
    "\n",
    "각 후보 데이터마다 좌표를 중심으로 50x50mm의 여러 장의 2D 패치를 추출했다. 모든 결절들은 30mm 이하의 크기이기 때문에 패치는 결절의 모습을 완전히 담을 수 있다. 그리고 패치의 크기를 64x64로 늘려 CT데이터의 일반적인 해상도인 0.78mm에 맞추었다. 각 픽셀의 intensity range는 (-1000, 400 HU)에서 (0,1)로 재조정하였다. 패치는 총 9장으로, 각각 후보군의 좌표를 중심으로 하는 50x50x50mm 육면체를 sagittal, coronal, axial 평면으로 잘라 추출했다.\n",
    "\n",
    "### (3) False Positive Reduction : 2D Convnets Configuration\n",
    "\n",
    "이 단계는 여러 CNN을 사용한 멀티뷰 구조로 이루어진다. 후보군은 9장의 패치로 나눠지는데 9개의 2D CNN에 의해 각각 학습된다. 각 CNN은 3개의 Convolutional + Max-pooling Layer로 구성된다. input 사이즈는 패치의 크기인 64x64이다. 첫 번째 레이어는 5x5x1 사이즈의 24개의 커널로, 두 번째 레이어는 3x3x24 사이즈의 32개의 커널로, 세 번째 레이어는 3x3x32 사이즈의 48개의 커널로 이루어진다. 커널들은 랜덤하게 초기화되지만 학습을 거듭하며 분류정확도를 높이는 쪽으로 최적화된다. 마지막 레이어는 16개의 output을 출력하는 fully connected layer이다.\n",
    "\n",
    "### (4) False Positive Reduction : Convnets Fusion\n",
    "\n",
    "16개의 output을 병합해 결과는 내는 단계이다. 총 3개의 대표적인 접근법이 있다.\n",
    "\n",
    "+ **Commitee-Fusion** : 가장 일반적으로 사용되는 방식으로, 9개의 CNN에 각각 classification을 위한 fully connected layer를 적용해 서로 다른 분류결과를 낸다. 이 결과는 Softmax함수를 거치므로 0~1의 값을 가지는데, 이 값들을 곱의 법칙을 이용해 계산해 최종 확률을 뽑아낸다.\n",
    "+ **Late-Fusion** : 9x16개의 output을 한번에 fully connected layer에 넣고 분류하는 방식으로, 서로 같은 parameter를 공유하게 되며 각 패치들 간의 상관관계가 반영된다는 특징이 있다.\n",
    "+ **Mixed-Fusion** : 위 두 방식을 혼합한 구조로 그림을 보면 이해가 빠르다.\n",
    "\n",
    "### (5) Training\n",
    "\n",
    "+ **LIDC-IDRI** 데이터셋에서 888개를 선정해 5-fold cross-validation을 수행했다. 888개를 비슷하게 5세트로 나누고 3세트는 학습에, 1세트는 validation에, 나머지 1세트는 testing에 사용했다.\n",
    "+ 모델 최적화를 위해 **RMSProp**이라는 학습 알고리즘을 사용했다.\n",
    "+ 0.5의 **Dropout**을 최초 fully connected layer에 적용했다.\n",
    "+ 3 에폭 이후에도 성능의 향상이 없을 때까지 학습을 진행했다.\n",
    "+ **가중치**는 Glorot and Bengio가 제안한 방식으로 초기화했고, **편향**은 0으로 초기화했다.\n",
    "\n",
    "### (6) Data Augmentation\n",
    "\n",
    "오버피팅을 방지하기 위한 Data Augmentation\n",
    "\n",
    "+ **Training Data Augmentation** : training과 validation에 적용했고, 결절이 비결절보다 훨씬 적으므로 결절에만 Augmentation을 수행했다. Position은 각 축마다 1mm씩, Scale은 패치의 크기를 40, 45, 50, 55mm로 조정해 사용했다. 1mm로 Position을 조정한 이유는 최소크기인 3mm의 결절을 유지하기 위해서이다. 랜덤 upsampling을 사용해 데이터의 밸런스를 맞췄다.\n",
    "\n",
    "+ **Test Data Augmentation** : CNN의 성능향상을 위해 testing data에 적용했다. Test-data augmentation(TDA)은 결절과 비결절 모두 40, 45, 50, 55mm로 scaling 했다. augmented data마다 예측된 결과를 평균내서 마지막 결과를 얻었고, 이 결과는 상호보완적인 정보를 제공함으로써 결절의 크기의 다양성에 대해 더 정확하고 강인한 예측을 가능하게 할 것이다.\n",
    "\n",
    "\n",
    "### (7) Evaluation\n",
    "\n",
    "AUC(area under the ROC curve)와 CPM(Competition Performance Metric) 두 방법을 사용해 평가했다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Results\n",
    "\n",
    "### (1) Candidates Detection\n",
    "\n",
    "세 알고리즘은 각각 85.7%, 36.1%, 31.8%의 민감도를 가졌지만, 세 개를 합친 결과는 그 시너지로 인해 94.4%의 민감도를 기록하며 1186개의 결절 중 1120개를 후보군으로 분류했다. 이 중 결절일 확률이 아주 낮은 데이터를 제거해 1106개의 결절을 사용했다.\n",
    "\n",
    "### (2) False Positive Reduction\n",
    "\n",
    "+ Table 2 : Augmented된 데이터의 정보\n",
    "+ Table 3 : fusion method로 구분한 평가 결과로, **fusion method와 view number**가 중요한 변수로 작용한다는 것을 알 수 있다.\n",
    "+ Table 4 : 알고리즘의 강인함을 평가하기 위해 반전데이터로 성능평가를 했는데, 반전과 비반전 데이터 둘 다 사용할 경우 성능이 강인해진다.\n",
    "+ Table 5 : ANODE09 데이터셋에 대한 각 CAD 시스템들의 성능 비교 - solid set만 사용했을 때는 ConvNets-CAD가 좋지만 세 알고리즘을 합치고 확률이 낮은 결절데이터는 제거한 reduced set은 오히려 안좋은 성능을 보인다. *(ANODE09데이터셋에는 solid 알고리즘에 알맞는 데이터들이 있기 때문인듯.. 즉 제안된 시스템이 일반화 능력이 충분하다고는 볼 수 없다는 말)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Discussion\n",
    "\n",
    "+ 이 논문에서는 멀티뷰 CNN을 사용한 폐결절 탐지 CAD 시스템을 제안했다. 기존 시스템과는 다르게 LIDC-IDRI 데이터셋에 대해 더 나은 성능을 보여주며 CNN의 잠재력을 증명했다.\n",
    "\n",
    "+ 우리는 기존의 candidate detection들을 혼합해 적용했고 그 시너지로 탐지 능력을 93.3%까지 높였다. subsolid와 large 그룹은 결절의 양이 많지 않았지만, 암으로 발전할 가능성은 더 높을 수 있기에 민감한 탐지가 중요하다.\n",
    "\n",
    "+ 연구 결과에서 **멀티뷰의 갯수가 크면** 성능이 높아지고, **Committee-Fusion 기법**을 사용할 때 성능이 높아지는 것을 알 수 있었다. 또한 ANODE09 데이터셋에 적용한 결과 이런 완전히 다른 형식(ANODE09는 LIDC-IDRI와 다르게 영상을 랜덤하게 뽑아준다는 차이점이 있음)의 데이터셋에서도 제안된 시스템이 다른 것들을 뛰어넘는 것을 볼 수 있다. *(비록 reduced set에서는 그러지 못했지만.. 따라서 후보군 탐지 알고리즘을 손봐야 할 필요성이 있다.)*\n",
    "\n",
    "+ 이 프레임워크는 Theano로 구현되었고, GeForce Gtx TITAN X로 학습되었으며, 멀티뷰가 1, 3, 9일 때 각각 315초, 980초, 그리고 3465초의 학습시간을 가졌다.\n",
    "\n",
    "+ 폐결절 탐지 CAD 시스템을 실제로 사용하려면 **민감도 성능이 향상**되어야만 한다. 연산량이 증가하겠지만 **3D로 input**을 받는다거나, 패치에서는 추출할 수 없는 context feature 등의 **다른 feature들을 추가**하는 등의 시도가 성능향상을 이뤄낼 것이라고 생각한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Conclusion\n",
    "\n",
    "+ *세 가지 알고리즘을 사용한 후보군 추출 단계는 다소 naive한 측면이 있고, 저자도 민감도 성능을 향상시켜야 한다고 말한다. 단순한 ensemble 구조가 아닌 논리가 담긴 시스템을 개발해야 될 필요가 있다.*\n",
    "+ *다른 데이터셋에 적용했을 때 일반화 능력이 떨어진다. 멀티뷰 갯수가 크면 성능이 높아진다는 결과로부터 멀티뷰 사이의 연관관계를 학습단계에 추가할 수 있다면 더 나은 성능이 나올 가능성도 있다고 생각한다.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
