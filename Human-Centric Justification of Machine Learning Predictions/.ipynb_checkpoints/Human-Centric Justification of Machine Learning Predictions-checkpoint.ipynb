{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human-Centric Justification of Machine Learning Predictions\n",
    "\n",
    "by Or Biran & Kathleen McKeown from Columbia University (IJCAI-17)\n",
    "\n",
    "## 1. 소개\n",
    "\n",
    "사람들 사이에서도 본인의 주장을 설득시키기 위해서는 그 근거가 필요하듯이, 기계학습으로 얻어진 결과 역시 그 성능이 아무리 좋더라도 설명이 불가능하다면 신뢰도가 떨어진다. 그렇다면 기계학습의 블랙박스 학습과정을 설명할 수 있는 방법은 없는 것일까?\n",
    "\n",
    "이 논문은 기계학습의 결과를 설명하기 위해 Natural Language Generation(NLG)을 사용해 기계학습의 결과를 간단하게 설명해주는 모델을 제시했다. 먼저 관련된 선행 연구로 Robnik-Sikonja & Kononenko의 'Prediction Interpretation (2016)' 논문을 보면 '해석이 불가능한 모델'의 특정 예측행위에 대해 '해석 가능한 선형모델' 등을 생성하는 방법을 제시한다. 사실 이 논문이 다루는 모델은 (1) 전문가나 통계학자에 의해 해석 가능한 (2) 시각화 등으로 나타낼 수 있는 낮은 복잡도의 모델이기 때문에 위 선행연구의 도움을 받을 수 있다. 즉, 위 연구로부터 설명 불가능한 모델에서 설명 가능한 모델을 만들어내고, 그 모델을 자연어로 설명하는 것이 이 논문의 목표인 것이다. 이러한 자연어 설명으로부터 사용자는 정확히 모델의 예측이 옳은지 그른지 판단할 수 있고, 기계의 결과에 대해 신뢰감을 얻을 수 있다. 아래 그림은 여기서 제안한 모델의 결과 예시이다.\n",
    "\n",
    "![fig01](https://github.com/siniphia/PaperReview-MachineLearning/blob/master/Human-Centric%20Justification%20of%20Machine%20Learning%20Predictions/fig01.PNG?raw=true)\n",
    "\n",
    "---\n",
    "## 2. 관련 연구\n",
    "\n",
    "### 의료분야\n",
    "\n",
    "요새는 특히 의료분야에서 모델에 대한 해석이 중요하게 여겨지는 추세이다. 생명에 직접적으로 관련된 이 분야의 특성상 중요할 수밖에 없긴 하다. \n",
    "\n",
    "+ Lacave and Diez, 2002\n",
    "+ Yap et al., 2008\n",
    "+ Helldin and Riveiro, 2009\n",
    "\n",
    "### 추천시스템\n",
    "\n",
    "영화추천시스템의 경우 선호하는 영화배우 등의 '강력한 특징'을 사용하는 간단한 방법에서 답을 찾아내고 있다. 이런 '강력한 특징' 기반의 방법론은 기존 사용자의 히스토리 등의 다른 특징을 사용하는 접근법보다 쉽고 우수하다고 한다.\n",
    "\n",
    "+ Sinha and Swearingen, 2002\n",
    "+ Bilgic and Mooney, 2005\n",
    "+ Symeonidis et al., 2009\n",
    "+ Papadimitriou et al., 2012\n",
    "\n",
    "### 인공지능 문학\n",
    "\n",
    "이 분야는 Nomogram 등의 시각화 기술을 이용해 전문가의 모델 분석을 돕는 방향으로 이뤄지고 있다.\n",
    "\n",
    "+ Lubsen et al., 1978 : Nomogram의 최초 등장\n",
    "+ Mozina et al., 2004 : Naive Bayes 모델에 적용\n",
    "+ Jakulin et al., 2005 : SVM 모델에 적용\n",
    "+ Szafron et al., 2003 : Naive Bayes 모델에 대한 더 상세한 시각화 프레임워크 제안\n",
    "\n",
    "### 기타\n",
    "\n",
    "위 연구들은 거의 특정 모델에만 적용되는 방법론이지만 어떤 모델에도 적용 가능한 일반화된 프레임워크도 연구된 바 있다.\n",
    "\n",
    "+ Robnik-Sikonja and Kononenko, 2008, Kononenko et al., 2013 : 특정 특징의 효과를 알기 위해 해당 특징을 제거했을 때와 사용했을 때의 결과를 비교하는 컨셉이다. 비교값은 시각화되어 나타난다.\n",
    "+ Baehrens et al., 2010 : Explanation Vector라는 다른 접근법을 사용해 가장 중요한 특징들의 효과를 알아낸다.\n",
    "+ Ribeiro et al., 2016 : 부분적으로 해석가능한 모델을 학습시켜 전체 모델이 그 영역에서 어떻게 행동할지 추측한다. ★\n",
    "\n",
    "그 외 관련된 연구들\n",
    "\n",
    "+ Rahwan and Simari, 2009 : Computational Argumentation\n",
    "+ Vlek et al., 2016; Timmer et al., 2017 : Explanation of Statistical Information in Forensic Science\n",
    "+ Tullio et al., 2007; Lim and Dey, 2010 : Explanation in Context Aware Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. 특징군 분류 및 설명\n",
    "\n",
    "모델을 해석하려면 예측에 가장 큰 영향을 미치는 요소들을 찾는게 일반적인 접근법이다. 따라서 첫번째로 각 **특징들의 역할**을 알아내야 한다. 이 논문에서는 역할을 크게 두 가지 요소(Effect, Importance)로 나눴고 각 특징마다 이 요소들의 영향을 Linear Discriminant Function을 활용해 알아내서 9가지 특징군으로 분류했다. 분류 카데고리는 아래 표 참조.\n",
    "\n",
    "+ **Effect(영향력)** : 해당 특징이 예측결과에 어떤 효과를 미치는가\n",
    "+ **Importance(중요도)** : 해당 특징 자체가 (그 특징의 실제 값과는 관계없이) 예측결과에 얼마나 큰 영향력을 발휘하는가\n",
    "\n",
    "![table01](https://github.com/siniphia/PaperReview-MachineLearning/blob/master/Human-Centric%20Justification%20of%20Machine%20Learning%20Predictions/table01.PNG?raw=true)\n",
    "\n",
    "아래는 분류한 9가지 특징군에 대한 설명이다.\n",
    "\n",
    "### Evidence Group\n",
    "\n",
    "+ **Normal Evidence** : 자주 등장하며 중요도도 영향력도 높은 일반적인 특징이다.\n",
    "+ **Exceptional Evidence** : 중요도는 낮지만 영향력은 높은 예외적인 특징으로 잘 등장하지 않는다. 이런 특징은 중요도는 낮지만 값 자체가 굉장히 크다는 속성이 있다. 따라서 이 특성의 값이 보통 수준일 경우 별 영향력이 없다.\n",
    "+ **Contrarian Evidence** : 이 특징은 중요도가 네거티브이기 때문에 값이 마이너스일 때만 등장하며 거의 발견되지 않는다.\n",
    "\n",
    "### Missing Evidence Group\n",
    "\n",
    "+ **Missing Evidence** : 긍정적 중요도는 높지만 어떤 경우에는 큰 영향력을 발휘하지 못하는 특징이다. 즉, 이 특징이 있는 예측은 틀릴 가능성이 다소 있다는 것을 암시하기 때문에 꽤 중요한 요소이다.\n",
    "+ **Negligible** : 영향력도 중요도도 낮기 때문에 이 모델에서 제외시킨다.\n",
    "+ **Missing Counter-Evidence** : 위와 유사하게 부정적인 중요도가 높지만 큰 영향력을 발휘하지 못하므로, 오히려 틀릴 것 같은 예측이 맞을 가능성이 존재한다.\n",
    "\n",
    "### Counter-Evidence Group\n",
    "\n",
    "긍정적 중요도가 크더라도 근본적으로 큰 영향력을 가질 수 있기 때문에 예측에 대한 의심을 하게 만드는 특징이다. 따라서 신뢰도 측면에서 굉장히 중요한 특성군이다. 이쯤 되면 부가 항목에 대해 구체적인 설명이 없어도 이해할 수 있을 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. 자연어생성\n",
    "\n",
    "위의 특징군 분류를 바탕으로 자연어를 생성해준다. Core Message와 Secondary Message 두 단계로 자연어를 생성한다.\n",
    "\n",
    "1. **Core Message** : 위에서 정의한 9가지 특징군의 특성에 대해 설명해준다. 각 특징군마다 표현이 다른 5개의 자연어로 사전 정의되어 있다.\n",
    "2. **Secondary Message** : 먼저 중요한 특징들을 골라서 왜 이 특징이 중요한지에 대해 평이한 문장으로 설명해준다. 특징들은 Barzilay & Lapata의 논문에 제안된 'Energy Minimization Framework'를 사용해 선택되며, 문장은 각 특징의 이름으로 위키피디아에서 검색되어 사용된다. 특징의 이름이 실생활의 개념과 다를 수 있기 때문에 모든 특징에 Secondary Message가 추가되지는 않으며, 기준을 넘어서는 너무 긴 문장은 제외된다.\n",
    "3. **Message Ordering** : 다음으로 선택된 Core와 Secondary Message를 정렬한다. Biran & McKeown의 논문에서 Prasad et al.의 Penn Discourse TreeBank를 이용해 트리의 최상단 노드 4개로 연관성이 높은 데이터를 뽑아내는데,  노드 중 2개인 Expansion과 Comparison만을 이용해 고유 알고리즘으로 정렬했다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. 평가방법\n",
    "\n",
    "이 알고리즘을 주식시세예측 업무에 적용해 보았다. 야후주식에서 얻어온 487개의 기업을 대상으로 23개의 특징을 이용해 2년간의 데이터로 학습시켰고 향후 10일간의 시세를 Logistic Regression으로 예측했다. 하루 뒤의 시세예측 정확도를 58.5%였고 이 예측결과를 네 개의 포맷(노설명, 그림설명, 텍스트설명, 그림+텍스트)으로 준비해 사람들에게 제공했다.\n",
    "\n",
    "CrowdFlower라는 클라우딩 실험 사이트에서 33명의 지원자를 받아 수행했으며, 사용 후 세 가지 질문에 답하게 했다. (1) 예측 결과에 동의하는지, (2) 예측 결과가 투자여부 판단에 도움이 되었는지, (3) 예측 결과에 만족했는지가 그것이다. 모델정보 및 사용자 응답결과는 아래 표 참조.\n",
    "\n",
    "![table03](http://localhost:8888/files/Documents/GitHub/PaperReview-MachineLearning/Human-Centric%20Justification%20of%20Machine%20Learning%20Predictions/table03.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. 결론\n",
    "\n",
    "### 결론\n",
    "\n",
    "1. 분류기의 예측 정확도와 상관없이 예측에 관한 추가 설명이 사용자들 입장에서 유용하다는 것을 알 수 있었다.\n",
    "2. 특히 그 효과가 '이미지 < 텍스트 < 이미지 + 텍스트'라는 사실로부터 **텍스트 설명이 사용자의 만족감에 큰 영향**을 미친다.\n",
    "3. 설명이 주어진 경우 오히려 예측결과에 동의한다는 비율이 줄어들었는데, 이것은 사용자에게 더 많은 정보가 주어짐에 따라 자의적 판단을 할 수 있게 되었기 때문인 것 같다.\n",
    "4. 결과로부터 정확한 통계적 추론을 낼 수는 없지만 설명을 제공하는 것에 대한 중요도는 자명하게 드러난다.\n",
    "5. 이 모델은 Java 패키지 **'PreJu'**라는 이름으로 오픈되어 있다.\n",
    "\n",
    "### 후행 연구\n",
    "\n",
    "1. 이 논문이 간과한 점은 특징들 간의 **상호연관성**이다. 높은 관련성을 가진 특징들을 Feature Aggregation을 통해 그룹핑해 사용하는 방법도 시도해 볼만하다.\n",
    "2. 또한 PCA 등을 통한 최적화 작업도 시도해 볼만하다.\n",
    "\n",
    "---\n",
    "\n",
    "+ 딥러닝 모델은 굉장한 정확도 상승을 이루었지만, 메디컬 이미징 분야도 그렇고 실생활에서 사용하기 위해서는 블랙박스에 대한 사용자들의 불안감을 해소할 수 있어야 하며, 전문가 수준에서도 어떻게 그런 결과가 나왔는지 어느 정도 이해할 수 있어야 한다. 그런 점에서 이 논문은 추가 설명에 대해 기계학습 모델을 정당화시킨 결과가 사용자에게 긍정적인 영향을 미쳤다는 점을 보여주며 의미 있는 결과를 도출해 냈다고 생각한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
